{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "9a7d9a75",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Imports das bibliotecas\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns \n",
    "import os\n",
    "import glob\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score\n",
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "import re"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f22aa0b",
   "metadata": {},
   "source": [
    "Visualizar dados de uma coluna do dataframe --> final[final['Origem_Aba'] == 'true_label']\n",
    "Remover coluna de um dataframe --> final = final.drop(columns=['Unnamed: 0'])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "8e0c26e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Normalizando o arquivo labels.xlsx\n",
    "pyt1 = pd.read_excel('./vulnerable_files/labels/labels.xlsx', engine='openpyxl', sheet_name=None)\n",
    "merged = []\n",
    "special_tabs = ['codeql', 'bandit']\n",
    "\n",
    "for tab_name, df in pyt1.items():\n",
    "\n",
    "    if tab_name in special_tabs and 'label' in df.columns:\n",
    "        df['Vulline'] = df['label']\n",
    "        df = df.drop(columns=['label'])\n",
    "\n",
    "    # Cria uma nova coluna com o nome da aba atual\n",
    "    df['Sast_tool'] = tab_name\n",
    "    merged.append(df)\n",
    "\n",
    "df_pyt1 = pd.concat(merged, ignore_index=True)\n",
    "\n",
    "df_pyt1 = df_pyt1.drop(columns=['Unnamed: 0'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "881cad4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Normalizando o arquivo PyTy2_final_labels.xlsx\n",
    "pyt2 = pd.read_excel('./vulnerable_files/labels/PyTy2_final_labels.xlsx', engine='openpyxl')\n",
    "\n",
    "df_pyt2 = pd.DataFrame()\n",
    "df_pyt2['Filename'] = pyt2['Filename']\n",
    "df_pyt2['Vulline'] = np.nan\n",
    "\n",
    "colunas_sast = ['Mr. Chekideh', 'Semgrep', 'Bandit']\n",
    "\n",
    "df_pyt2 = pyt2.melt(id_vars=['Filename'] ,value_vars=colunas_sast, var_name='Sast_tool', value_name='Vulline')\n",
    "\n",
    "df_pyt2['Sast_tool'] = df_pyt2['Sast_tool'].replace(\"Mr. Chekideh\", \"true_label\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "873d5487",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Normalizando o arquivo siddiq_final_labelx.xlsx\n",
    "siddiq = pd.read_excel('./vulnerable_files/labels/siddiq_final_labels.xlsx', engine='openpyxl')\n",
    "\n",
    "df_siddiq = pd.DataFrame()\n",
    "df_siddiq['Filename'] = pyt2['Filename']\n",
    "df_siddiq['Vulline'] = np.nan\n",
    "\n",
    "colunas_sast = ['Mr. Chekideh', 'Semgrep', 'Bandit']\n",
    "\n",
    "df_siddiq = siddiq.melt(id_vars=['Filename'] ,value_vars=colunas_sast, var_name='Sast_tool', value_name='Vulline')\n",
    "\n",
    "df_siddiq['Sast_tool'] = df_siddiq['Sast_tool'].replace(\"Mr. Chekideh\", \"true_label\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "b647e3ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Unificando todos oa dataframes em um único\n",
    "df_final = pd.concat(objs=[df_pyt1, df_pyt2, df_siddiq])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "ab5ec908",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<>:65: SyntaxWarning: \"\\(\" is an invalid escape sequence. Such sequences will not work in the future. Did you mean \"\\\\(\"? A raw string is also an option.\n",
      "<>:65: SyntaxWarning: \"\\(\" is an invalid escape sequence. Such sequences will not work in the future. Did you mean \"\\\\(\"? A raw string is also an option.\n",
      "C:\\Users\\levim\\AppData\\Local\\Temp\\ipykernel_19076\\3668182045.py:65: SyntaxWarning: \"\\(\" is an invalid escape sequence. Such sequences will not work in the future. Did you mean \"\\\\(\"? A raw string is also an option.\n",
      "  labels_dist = exploded_labels.str.extract('\\((.*)\\)')[0].value_counts()\n"
     ]
    }
   ],
   "source": [
    "# Definindo funções úteis\n",
    "\n",
    "def unifyCweAndLine(df, columnName):\n",
    "    df[columnName] = df.apply(lambda row: f'{row[\"line\"]}({row[\"cwe\"]})', axis=1)\n",
    "    df = df.rename(columns={'filename':'Filename'})\n",
    "\n",
    "    df_aggregated = (\n",
    "        df.groupby(\"Filename\")[columnName]\n",
    "        .apply(lambda x: \",\".join(x))\n",
    "        .reset_index()\n",
    "    )\n",
    "    \n",
    "    return df_aggregated\n",
    "\n",
    "def remove_duplicates(cwe_list):\n",
    "    if isinstance(cwe_list, float) and np.isnan(cwe_list):\n",
    "        return []\n",
    "    else:\n",
    "        test = sorted(list(set(cwe_list.split(','))))\n",
    "        # print(test)\n",
    "        return test\n",
    "\n",
    "def reder(col, df):\n",
    "    temp = df[col][df[col].notna()].str.split(',').explode()\n",
    "    preds = (temp.index.astype(str) + '-' + temp)\n",
    "    preds = preds[preds.notna()].values\n",
    "    return preds\n",
    "\n",
    "def my_rec(labels, preds):\n",
    "    rec_samples = [x for x in preds if x in labels]\n",
    "    return len(rec_samples)/len(labels)\n",
    "\n",
    "def my_pre(labels, preds):\n",
    "    tp = [x for x in preds if x in labels]\n",
    "    if len(preds) == 0:\n",
    "        return 0\n",
    "    return len(tp)/len([x for x in preds if '-nan' not in x])\n",
    "\n",
    "def my_f1(precision, recall):\n",
    "    return 2 * (precision * recall) / (precision + recall)\n",
    "\n",
    "def bench_it(labels, preds, attack = ''):\n",
    "    if attack != '':\n",
    "        attack = '('+attack+')'\n",
    "    labels = [x for x in labels if attack.lower() in x.lower()]\n",
    "    attack.lower()\n",
    "    preds = [x for x in preds if attack.lower() in x.lower()]\n",
    "    \n",
    "    pre = my_pre(labels, preds)\n",
    "    rec = my_rec(labels, preds)\n",
    "    # if attack == '':\n",
    "    #     print(pre, 'labels:', labels, 'preds:', preds)\n",
    "\n",
    "    \n",
    "    #print(pre, labels, preds)\n",
    "\n",
    "    if (pre + rec) == 0:\n",
    "        return [pre, rec, 0]\n",
    "    def f1(precision, recall):\n",
    "        return 2 * (precision * recall) / (precision + recall)\n",
    "    return [pre, rec, f1(pre, rec)]\n",
    "\n",
    "\n",
    "def full_bench(preds, exploded_labels, dist_labels):\n",
    "    labels_dist = exploded_labels.str.extract('\\((.*)\\)')[0].value_counts()  \n",
    "\n",
    "    atts = list(labels_dist.index)\n",
    "    atts.append('')\n",
    "    sems = []\n",
    "    for attack in atts:\n",
    "        temp = bench_it(dist_labels, preds, attack)\n",
    "        temp.extend([attack if attack != '' else 'all', labels_dist[attack] if attack != '' else sum(labels_dist)])\n",
    "        sems.append(temp)\n",
    "    df = pd.DataFrame(sems, columns = ['Precision', 'Recall', 'F1-Score', 'Attack', 'Support'])\n",
    "    df = df.set_index('Attack')\n",
    "    return df\n",
    "\n",
    "def clear_data(df, column):\n",
    "    df[column] = df[column].astype(str)\n",
    "    df[column] = df[column].apply(lambda x: re.sub(r'\\b0(\\d{1})\\b|\\b0(\\d{2})\\b', r'\\1\\2', x))\n",
    "    df[column] = df[column].apply(lambda x: re.sub(r'(CWE-\\d+)-0(\\d)', r'\\1-\\2', x))\n",
    "    df[column] = df[column].apply(lambda x: ','.join(remove_duplicates(x)))\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "8ab3c522",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Criando dataframe só com as ground truths e realizando limpeza\n",
    "\n",
    "def remove_spaces(text):\n",
    "    return re.sub(r'(\\d) +\\(', r'\\1(', text)\n",
    "\n",
    "\n",
    "df_ground_truth = df_final[df_final['Sast_tool'] == 'true_label']\n",
    "df_ground_truth = df_ground_truth.copy()\n",
    "\n",
    "df_ground_truth['Vulline'] = df_ground_truth['Vulline'].apply(lambda x: re.sub(r'\\b0(\\d{1})\\b|\\b0(\\d{2})\\b', r'\\1\\2', x))\n",
    "df_ground_truth['Vulline'] = df_ground_truth['Vulline'].apply(remove_spaces)\n",
    "df_ground_truth['Vulline'] = df_ground_truth['Vulline'].str.replace(', ', ',')\n",
    "df_ground_truth['Vulline'] = df_ground_truth['Vulline'].apply(lambda x: ','.join(remove_duplicates(x)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "dc389358",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Criando dataframe com ground truths e com resultados do bandit, e realizando limpeza dos dados\n",
    "bandit = pd.read_json('C:/Users/levim/projetos/results/formatted_bandit.json')\n",
    "semgrep = pd.read_json('C:/Users/levim/projetos/results/formatted_semgrep.json')\n",
    "\n",
    "bandit_aggregated = unifyCweAndLine(bandit, 'bandit')\n",
    "semgrep_aggregated = unifyCweAndLine(semgrep, 'semgrep')\n",
    "\n",
    "df_bandit = df_ground_truth.merge(bandit_aggregated, on=\"Filename\", how=\"left\")\n",
    "df_semgrep = df_ground_truth.merge(semgrep_aggregated, on=\"Filename\", how=\"left\")\n",
    "\n",
    "df_bandit = clear_data(df_bandit, 'bandit')\n",
    "df_semgrep = clear_data(df_semgrep, 'semgrep')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "d9de8603",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Tool</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1-Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Bandit</td>\n",
       "      <td>0.288462</td>\n",
       "      <td>0.057803</td>\n",
       "      <td>0.096308</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Semgrep</td>\n",
       "      <td>0.677778</td>\n",
       "      <td>0.117534</td>\n",
       "      <td>0.200328</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Tool  Precision    Recall  F1-Score\n",
       "0   Bandit   0.288462  0.057803  0.096308\n",
       "1  Semgrep   0.677778  0.117534  0.200328"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bandit_preds = reder('bandit', df_bandit)\n",
    "semgrep_preds = reder('semgrep', df_semgrep)\n",
    "\n",
    "exploded_labels = df_bandit['Vulline'].str.split(',').explode()\n",
    "dist_labels = (exploded_labels.index.astype(str) + '-' + exploded_labels).values\n",
    "\n",
    "results_bandit = bench_it(dist_labels, bandit_preds)\n",
    "results_semgrep = bench_it(dist_labels, semgrep_preds)\n",
    "\n",
    "data = {\n",
    "    'Tool': ['Bandit', 'Semgrep'],\n",
    "    'Precision': [results_bandit[0], results_semgrep[0]],\n",
    "    'Recall': [results_bandit[1], results_semgrep[1]],\n",
    "    'F1-Score': [results_bandit[2], results_semgrep[2]]\n",
    "}\n",
    "\n",
    "final_result = pd.DataFrame(data)\n",
    "final_result"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.14.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
